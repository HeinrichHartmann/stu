#
# Make -m random be more random. 
#  * re-start from the root at each iteration
#  * also open new dependencies randomly before finishing the currently
#    open children 
#

#==== Small features that complete what we already have ====

#
# Have an option to read a list of targets from a file.  Or allow
# something like
#    
#     stu [FILENAME]
#
# on the command line.  We may also support more Stu syntax on the
# command line:
#
#     stu ?FILENAME   # Rebuild FILENAME only if it already exists
#     stu !FILENAME   # Build FILENAME only if it does not exist yet
#
# We may introduce a (-c) option to give full Stu expressions:
#
#     stu -c '?[FILENAME]'
#
# We may also introduce a new option for passing a target without extra
# allowed syntax, e.g.
#
#     stu -T '?F'
#
# would build a file named '?F'. 
#

#
# Assign a name to a dynamic variable.  Useful when the name of the file
# contains characters that are not allowed in shell variable names. 
#

prog:  prog.c
	$[CFLAGS = config/CFLAGS]
{ 
	gcc $CFLAGS -c prog.c -o prog
}

#
# Hard-coded content
#

# Will the file begin and end with spaces?
CFLAGS = { -g -Werror }

# Will the file begin with a newline? 
LIST = {
aaa
bbb
ccc
}

# Will indentation be preserved? 
LIST2 = {
   aaa
   bbb
   ccc
}

# Empty file
A = {}

#
# Have an option which makes Stu output statistics when it is finished:
# * runtime information
# * number of processes run (succeeded + failed) 
# * etc. 
#

#
# Recognize and prevent recursive Stu.
# Via an environment variable?  Have an option to allow it anyway. 
#
# Option to ignore the check: -y.
#

#
# Copy rule
#

a.bib = ../bib/references.bib;

# Allow the same-name shortcut (ending in slash or not [with fopenat]):
konect.bib=  ../../projects/konect/;
konect.bib=  ../../projects/konect;

#
# Make -v be better.  Make it output dependencies and traces. 
#

#
# Support $STU_SHELL for alternatives to /bin/sh. 
#

#==== Big features that complete what we already have ====

#
# Phonies in dynamics
#

# A will depend on the content of B, C and D. 
A:  [@x];
@x: B C D;

# Needs each phony to store the list of files it depended on, and is
# thus non-trivial to implement. 

#
# Assignment features
#

# Multiple names result in catenation
A = B C D;

# Combine with phony target
A = @x;
@x:  B C D;

# Combine with dynamic target
A = [X];
<X { echo B C D }

#
# Multiple targets declare a command that is able to build multiple
# files at once.
#

# Basic case:  two files are created 
$NAME.eps $NAME.runtime:  calculate {
	./calculate $NAME -o $NAME.eps --runtime=$NAME.runtime
}

# Can also be used to define phony shortcuts 
@bidd.$NETWORK plot/bidd.a.$NETWORK.eps: { ... }

# * They must all contain the same set of parameters. 
# * Only one can have an output redirection. 
# * If the desired target exists but not other targets, does that make
#   the rule be executed?  

# This will also allow to define multiple files as present:
A B C;

# This will allow a lone semicolon as a no-op:
;

#
# When reporting an error, always report how the .stu file was included
# by another .stu file.  Use "light" traces in green, like GCC does.
# (Maybe only do this in verbose mode.) 
#

#
# Have a way for dynamic dependencies to contain \0-separated filenames,
# to avoid quoting. 
#

A: [B],0 { xargs -0 B ... }

>B:  {
	find ... -print0
}

# Alternatively, detect such files automatically. (e.g., any file
# containing the zero character is such a file, or using specific endings.)

#
# When including files using dynamic dependencies, we could make a
# difference between inclusion and import, as is done for %include and
# %import. 
#

A: [B];
A: [B],i; 

#
# Chain of commands are useful for dynamic dependencies
#

@bidd:  [>dep.bidd]:  <NETWORKS { sed -re 's,^,bidd.,' }

#
# Input redirection for a dynamic dependency or list is catenation
#

>all.gz:  <[files] { gz }

# Not very useful since it can be emulated very simply using cat:
>all.gz:  [<files] { xargs cat | gz }

>A: <(B C) { sed -re '...' }

# With phonies
>A: <@x { sed -re '...' }
@x:  D E F;

# With dynamic dependencies
>A:  <[deps] { sed -re '...' }
>deps { ... }

#
# Line number syntax:  A preprocessor-like construct that gives a new
# filename and line number, such that error messages from Stu can point
# to the original file, not the generated file.  Analogous to the
# preprocessors #line directive.  Useful in dynamic dependencies. 
#

%line ...

#
# Support -f - to read in STDIN?
#

#
# Make the argument to the -j option optional.  (not possible with
# standard getopt()). 
#

#
# Advanced file inclusion 
#

# Include rules for C++ compilation; may search within predefined paths
# ($STUPATH) 
%include c++.stu
 
# Import all rules from subdirectory; will prepend the directory name to
# all targets.  Can take a directory name to denote the file main.stu
# within it. 
%import src/main.stu
%import src/

#
# Support these options from Make:
#   -B 		    Remake all targets regardless of dates
#   -o FILENAME	    Never rebuild that file ("old")
#   -q 		    Question mode 
#

#
# A 'what-if' option that does not run anything but shows what would be
# done.  (Not possible to do for dynamic dependencies.) (Called -n in
# Make)
#

# 
# An option to consider all targets up to date.  I.e., execute only the
# minimum to get the given files built. 
#

#
# An option for automatic logging:  write all output (stdout/stderr) of
# commands to a file (a different file per target).  Use the -l option. 
#

# 
# Think again about using /bin/sh -x. 
#   + each command is output as it is executed
#   - when a loop is executed, many lines are output
#   ~ commands are prefixed with '+ '
#   + environment variables are replaced with their values in the output
#   - we still would have to prefix the output with the value of
#     variables, since in many cases commands don't contain environment
#     variables (but only pass them the called programs)
#

#
# -m bfs (breadth-first order) and -m target (pseudotarget by target
# name) 
#

#==== New features that change extend the Stu drastically ====

#
# How to declare additional command interpreters.  Note:  we may use
# another character than the backslash. 
#

A.mat:  B.mat C.mat 
\octave{
	% This command will be executed by the Octave wrapper, and
	% read/write the three matrices automatically. 
	A = B * C;
}

octave:  octave-command {
	# This will be executed whenever A.mat is built, and the three
	# variables used below will be filled by Stu with the dependencies,
	# the target and the command, which are worked on by the script
	# ./matlab to invoke Matlab accordingly. 
	./octave-command "$STU_DEPENDENCIES" "$STU_TARGET" "$STU_COMMAND"
}

# A shell script that converts command to correct Octave scripts.  E.g.,
# it will load B.mat and C.mat as the variables B and C, and will save
# the generated variable A into A.mat. 
octave-command;

# Interpreters can be chained
\matlab-or-octave:  \octave;

# This may get problematic with finding the end of a command when
# programming languages use unusual quoting mechanisms and ways of
# pairing parenthesis-like characters. 

#
# Allow to handle symlinks as files in themselves, i.e., check for their
# own existence and their own timestamp.  This should not be the default
# as the current behaviour is more often useful, but should be available
# as a possibility. 
#

#
# Nested rules.  Good for dependencies that are used only once. 
#

A: (B: C { cp C B}) (D: E {cp E D}) { cat B D >A }
# This is quite hard to read, honestly. 

#
# Alternative dependencies
#

A:  B | C { ... }
A:  (B C) | (D E) { ... }

#
# Set intersection with '&'
#

@x:  (A B C) & (B C D);
# is the same as
@x:  B C;

#
# Index-wise concatenation with '|'
#

@x:  (A B) | (X Y);
# is the same as
@x:  AX BY;

# This is not really useful, though

#
# Set difference with '\'
#

@plots:  dat/plot.([dat/NETWORKS] \ enron).eps;

#
# Phonies can have content.  This will be executed at every Stu
# invocation. 
#

# Their definition:
@NAME = { linux }
@NAME2 = @NAME;
>@NAME { ./printname }

# Their use:
file:  <@NAME { sed -re '...' >file }
result.eps:  $[@NAME] { ./compute --name "$NAME" }

# This might be used like variables in Make, but the result will be that
# targets depending on them will always be rebuilt.  It would thus only
# make sense together with fingerprinting. 

#
# Allow regular expressions in parameters, e.g. for single-character
# parameters.  This will also make it possible to allow contiguous
# parameters, and giving a list of possible values for a parametrized
# rule. 
#

# Allow contiguous parameters
list.${X:.}${Y:.} {
	compute -x $X -y $Y >list.${X}${Y}
}

# Exclude certain characters from parameter names 
web.${NETWORK:[^.]+}

# Specify a list of values
${NAME:ref|ukob|tuberlin}.bib:  bibs-A/${NAME}.bib
{ cp bibs-A/$NAME.bib $NAME.bib }
$NAME.bib:  bibs-B/$NAME.bib
{ cp bibs-B/$NAME.bib $NAME.bib }

# Exclude slashes
${NAME:[^/]+}.bib: ...;

#
# When an error is output, the column number must take into account
# unicode characters.  In this example, the opening { must be reported
# to be at character 13.  This was implemented, but was decided to be
# too slow.  
#

éäçöôüœß柏林: {

#
# Recursion at the rule level is not allowed at the moment, but could
# be.  The problem is how to recognize infinite recursion. 
#

# Example 1:  Recursion at the rule level is needed to implement correct
# C source dependency. 

# Example 2:  building A.gz.gz does not work. 
$NAME.gz:  $NAME {
	gzip -c $NAME >$NAME.gz
}
A:  {
    echo 'Hello, World!' >A
}

#
# Fingerprinting instead of timestamps is a feature that's implemented by quite
# a few Make replacements.  This could also be combined with
# preprocessors which ignore whitespace, etc.  Can also be used for the
# commands embedded in Stu files, but then again we don't want to
# rebuild everything just because a command changed. 
#

#
# Let Stu itself be multithreaded.  Very complex to implement, and has
# only very little benefit since Stu already starts many processes.
# Would only make sense in scenarios with thousands of processes, which
# would only make sense on machines with thousands of cores. 
#

#
# On each call to Stu, the whole dependency tree is walked.  Allow this
# to be skipped in some smart way, perhaps using inotify or a similar
# interface.  This would allow a "Stu demon" that runs continuously and
# rebuilds targets as soon as they need to. 
#

#
# Provide a set of include-stufiles for common tasks, such as C
# programs, tex projects, etc. 
#

#
# Make trivial dependencies transitive across phonies, like it already
# is for existence-only and optional dependencies. 
#

#
# The current setup of Stu (and also Make) means that when nothing is to
# be done, Stu still has to walk the complete dependency tree and stat()
# every file.  For large projects, this may be come very slow.  Instead,
# have a Stu daemon which uses inotify or similar to notice changes.
# There are many practical issues with that, so that would be a huge
# change.  Would almost likely mean the server itself would do the
# building, and the client would only communicate with the server.  This
# also means the server would need to be multi-threaded. 
#

#==== Backward-incompatible features ====

#
# What happens with relative and absolute pathnames?  When two names
# refer to the same file?  Do we need to 'normalize' names?
#

# This will fail because ../../bib/[NAME].bib will match [NAME].bib.
# Instead, be able to write ./[NAME].bib
A:   a.bib b.bib c.bib;
$NAME.bib:  ../../bib/$NAME.bib { cp ... }
a.bib;

# Rules:
#     [NAME].bib:    a .bib file anywhere
#     ./[NAME].bib:  a .bib file in the current directory

# Remove trailing slash from directory names.
A:  ?tmp/ {...}
tmp: {...}

#
# Make 'single quotes' and "double quotes" behave like in the shell,
# i.e., with respect to what needs to be quoted inside them. 
#

'abc"def';
"network $NAME";
"aaa'bbb";

#
# String multiplication.  String multiplication is to work both with the
# binary operator '*' as well with juxtaposition.  Juxtaposition is
# backward incompatible, as in Version 1 strings like "A[B]" where
# interpreted as two dependencies, and with it they will be interpreted
# as one. 
#

A:	B * C;    	# Binary multiplication operator
A:	B * (C D); 	# Parentheses
A:	B[C];      	# Justaposition
A:	[B]C;      	# OK
A:	B(C D);    	# OK
A:	B(C D)E;   	# OK
A:	B[C]D;     	# OK
A:	[B] * [C]; 	# OK
A:	(A B) * (C D); 	# OK
A:	[B][C];         # OK
A:	(A B)(C D);     # OK
A:  (!B) * (C);    	# OK
A:  (?B) * (C);    	# OK
A:  (B) * (!C);    	# error
A:  (B) * (?C);    	# error
A:  (?B) * (!C);   	# error
A:  (<B) * (C);    	# OK
A:  (B) * (<C);    	# error
A:  !B(C D);       	# OK
A:  ?B(C D);       	# OK
A:  <B(C);         	# OK
A:  <B(C D);       	# error
A:  @B(C);         	# OK
A:  @B(C D);     	# OK
A:  B * @C;      	# error 
A:  $[B] * C;    	# error
A:  B * $[C];    	# error
A:  <B * C;      	# OK (or maybe:  ambiguous)
A:  B * <C;      	# error
A:  <B[C];		# OK iff C contains exactly one dependency (or an error)
@A: @B[C];       	# OK
A:  B@C;		# error
A.$X.$Y:  $X * $Y       # OK (can be contiguous)
A.$X.$Y:  $X.a * b.$X   # OK (despite duplicate parameter) 
A.$X.$Y:  $X. * $Y      # OK
A.$X.$Y:  $X * .$Y      # OK

# More examples

@headers:  (config parse build).h

@plot.all:   @plot.[NETWORKS];

@plot:    plot/[NETWORKS].eps;
